---
title: AI
date: 2021-03-17 11:35:36 +0800
categories: [AI]
tags: [总结]
---

## 组件

* 数据
    1. 海量
    2. 正确
* 模型
* 目标函数
* 优化算法

## 监督学习
### 回归
### 分类
### 标记
### 搜索
### 推荐系统
### 序列学习

最小化MSE,前提假设：数据是被高斯噪声破坏了

不确定风险的影响远远大于收益。 因此，我们需要将“预期风险”作为损失函数。 也就是说，我们需要将结果的概率乘以与之相关的收益（或伤害）

我们宁愿错误地分入一个相关的类别，也不愿错误地分入一个遥远的类别，这通常被称为层次分类(hierarchical classification)。 

我们把这个问题称为多类分类（multiclass classification）问题。 常见的例子包括手写字符识别  {0,1,2,...9,a,b,c,...} 。

学习预测不相互排斥的类别的问题称为多标签分类（multilabel classification）

搜索结果的排序也十分重要，我们的学习算法需要输出有序的元素子集。 换句话说，如果要求我们输出字母表中的前5个字母，返回“A、B、C、D、E”和“C、A、B、E、D”是不同的。 即使结果集是相同的，集内的顺序有时却很重要。


## 无监督学习
如果你的工作没有十分具体的目标，你就需要“自发”地去学习了。 （如果你打算成为一名数据科学家，你最好培养这个习惯。）

## 与环境互动
当环境可被完全观察到时，我们将强化学习问题称为马尔可夫决策过程（markov decision process）。 当状态不依赖于之前的操作时，我们称该问题为上下文赌博机（contextual bandit problem）。 当没有状态，只有一组最初未知回报的可用动作时，这个问题就是经典的多臂赌博机（multi-armed bandit problem）。

