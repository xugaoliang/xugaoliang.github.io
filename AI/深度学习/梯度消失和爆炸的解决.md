---
description: 梯度消失和爆炸的解决
---

# 梯度消失和爆炸的解决

* 选择合适的激活函数\
    使用Relu,不建议使用sigmoid和tanh,因为
    1. 区域小
    2. 容易梯度消散
* 选择合适的参数初始化方法
* 使用权重参数正则化
* 使用BatchNormalization
    1. 通过规范化操作将输出信号x规范化到均值为0，方差为1保证网络的稳定性
    2. 可以加大神经网络训练的速度
    3. 提高训练的稳定性
    4. 缓解梯度爆炸和梯度消散的问题
* 使用残差结构
    1. 极大地提高了神经网络的深度
    2. 很大程度上解决了梯度消散的问题
    3. 允许我们可以训练很深层的神经网络
    4. 残差结构可以看做解决梯度消散问题的最有效、最重要的方法
* 使用梯度裁剪